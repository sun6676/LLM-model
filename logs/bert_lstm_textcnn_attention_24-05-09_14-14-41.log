> creating model bert
> training arguments:
>>> num_classes: 2
>>> model_name: bert
>>> method_name: lstm_textcnn_attention
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 1e-05
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1715235281401
>>> checkpoint_dir: ./checkpoints
>>> log_name: bert_lstm_textcnn_attention_24-05-09_14-14-41.log
尝试从检查点继续训练: ./checkpoints\best_model.pth
新最佳模型已保存于: ./checkpoints\best_model_epoch1_acc98.29_loss0.3303.pth
1/10 - 10.00%
[train] loss: 0.3369, acc: 97.62, precision: 0.9766, recall: 0.9762, f1: 0.9762
[test] loss: 0.3303, acc: 98.29, precision: 0.9835, recall: 0.9829, f1: 0.9829
2/10 - 20.00%
[train] loss: 0.3303, acc: 98.30, precision: 0.9835, recall: 0.9830, f1: 0.9830
[test] loss: 0.3323, acc: 98.09, precision: 0.9816, recall: 0.9809, f1: 0.9809
新最佳模型已保存于: ./checkpoints\best_model_epoch3_acc98.31_loss0.3302.pth
3/10 - 30.00%
[train] loss: 0.3304, acc: 98.29, precision: 0.9834, recall: 0.9829, f1: 0.9829
[test] loss: 0.3302, acc: 98.31, precision: 0.9837, recall: 0.9831, f1: 0.9831
新最佳模型已保存于: ./checkpoints\best_model_epoch4_acc98.32_loss0.3301.pth
4/10 - 40.00%
[train] loss: 0.3302, acc: 98.31, precision: 0.9836, recall: 0.9831, f1: 0.9831
[test] loss: 0.3301, acc: 98.32, precision: 0.9837, recall: 0.9832, f1: 0.9832
新最佳模型已保存于: ./checkpoints\best_model_epoch5_acc98.33_loss0.3300.pth
5/10 - 50.00%
[train] loss: 0.3298, acc: 98.35, precision: 0.9840, recall: 0.9835, f1: 0.9835
[test] loss: 0.3300, acc: 98.33, precision: 0.9838, recall: 0.9833, f1: 0.9833
6/10 - 60.00%
[train] loss: 0.3297, acc: 98.35, precision: 0.9841, recall: 0.9835, f1: 0.9835
[test] loss: 0.3300, acc: 98.32, precision: 0.9838, recall: 0.9832, f1: 0.9832
7/10 - 70.00%
[train] loss: 0.3350, acc: 97.83, precision: 0.9784, recall: 0.9783, f1: 0.9783
[test] loss: 0.3322, acc: 98.11, precision: 0.9815, recall: 0.9811, f1: 0.9811
8/10 - 80.00%
[train] loss: 0.3303, acc: 98.30, precision: 0.9835, recall: 0.9830, f1: 0.9830
[test] loss: 0.3301, acc: 98.32, precision: 0.9837, recall: 0.9832, f1: 0.9832
9/10 - 90.00%
[train] loss: 0.3298, acc: 98.34, precision: 0.9840, recall: 0.9834, f1: 0.9834
[test] loss: 0.3301, acc: 98.31, precision: 0.9837, recall: 0.9831, f1: 0.9831
10/10 - 100.00%
[train] loss: 0.3301, acc: 98.32, precision: 0.9837, recall: 0.9832, f1: 0.9832
[test] loss: 0.3308, acc: 98.24, precision: 0.9830, recall: 0.9824, f1: 0.9824
Training time: 516398.55 seconds
best loss: 0.3300, best acc: 98.33
log saved: bert_lstm_textcnn_attention_24-05-09_14-14-41.log
