> creating model bert
> training arguments:
>>> num_classes: 2
>>> model_name: bert
>>> method_name: lstm_textcnn_attention
>>> train_batch_size: 64
>>> test_batch_size: 64
>>> num_epoch: 10
>>> lr: 2e-05
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1715769982085
>>> checkpoint_dir: ./checkpoints
>>> log_name: bert_lstm_textcnn_attention_24-05-15_18-46-21.log
尝试从检查点继续训练: ./checkpoints\best_model.pth
