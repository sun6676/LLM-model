> creating model lert
> training arguments:
>>> num_classes: 2
>>> model_name: lert
>>> method_name: bilstm_textcnn_attention
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 1e-05
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1724555112486
>>> checkpoint_dir: ./checkpoints
>>> log_name: lert_bilstm_textcnn_attention_24-08-25_11-05-12.log
尝试从检查点继续训练: ./checkpoints\best_model.pth
没有找到检查点文件，将从头开始训练。
新最佳模型已保存于: ./checkpoints\best_model_epoch1_acc98.27_loss0.3313.pth
1/10 - 10.00%
[train] loss: 0.3868, acc: 94.87, precision: 0.9488, recall: 0.9487, f1: 0.9487
[test] loss: 0.3313, acc: 98.27, precision: 0.9833, recall: 0.9827, f1: 0.9827
新最佳模型已保存于: ./checkpoints\best_model_epoch2_acc98.27_loss0.3307.pth
2/10 - 20.00%
[train] loss: 0.3335, acc: 97.97, precision: 0.9803, recall: 0.9797, f1: 0.9798
[test] loss: 0.3307, acc: 98.27, precision: 0.9833, recall: 0.9827, f1: 0.9827
3/10 - 30.00%
[train] loss: 0.3316, acc: 98.18, precision: 0.9825, recall: 0.9818, f1: 0.9819
[test] loss: 0.3311, acc: 98.22, precision: 0.9829, recall: 0.9822, f1: 0.9822
4/10 - 40.00%
[train] loss: 0.3329, acc: 98.02, precision: 0.9807, recall: 0.9802, f1: 0.9802
[test] loss: 0.3317, acc: 98.17, precision: 0.9823, recall: 0.9817, f1: 0.9817
5/10 - 50.00%
[train] loss: 0.3322, acc: 98.10, precision: 0.9817, recall: 0.9810, f1: 0.9810
[test] loss: 0.3406, acc: 97.23, precision: 0.9739, recall: 0.9723, f1: 0.9724
6/10 - 60.00%
[train] loss: 0.3316, acc: 98.17, precision: 0.9824, recall: 0.9817, f1: 0.9817
[test] loss: 0.3448, acc: 96.84, precision: 0.9684, recall: 0.9684, f1: 0.9684
新最佳模型已保存于: ./checkpoints\best_model_epoch7_acc98.27_loss0.3306.pth
7/10 - 70.00%
[train] loss: 0.3335, acc: 97.97, precision: 0.9803, recall: 0.9797, f1: 0.9798
[test] loss: 0.3306, acc: 98.27, precision: 0.9833, recall: 0.9827, f1: 0.9827
8/10 - 80.00%
[train] loss: 0.3329, acc: 98.02, precision: 0.9807, recall: 0.9802, f1: 0.9802
[test] loss: 0.3306, acc: 98.27, precision: 0.9833, recall: 0.9827, f1: 0.9827
9/10 - 90.00%
[train] loss: 0.3344, acc: 97.87, precision: 0.9791, recall: 0.9787, f1: 0.9788
[test] loss: 0.3310, acc: 98.22, precision: 0.9829, recall: 0.9822, f1: 0.9822
10/10 - 100.00%
[train] loss: 0.3318, acc: 98.13, precision: 0.9820, recall: 0.9813, f1: 0.9814
[test] loss: 0.3310, acc: 98.22, precision: 0.9827, recall: 0.9822, f1: 0.9822
Training time: 47374.21 seconds
best loss: 0.3306, best acc: 98.27
log saved: lert_bilstm_textcnn_attention_24-08-25_11-05-12.log
