> creating model lert
> training arguments:
>>> num_classes: 2
>>> model_name: lert
>>> method_name: lstm_textcnn_attention
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 1
>>> lr: 1e-05
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1736132849082
>>> checkpoint_dir: ./checkpoints
>>> log_name: lert_lstm_textcnn_attention_25-01-06_11-07-29.log
尝试从检查点继续训练: ./checkpoints\best_model.pth
没有找到检查点文件，将从头开始训练。
CUDA 已分配内存: 0 bytes
CUDA 已保留内存: 0 bytes
新最佳模型已保存于: ./checkpoints\best_model_epoch1_acc100.00_loss0.3587.pth
1/1 - 100.00%
[train] loss: 0.4482, acc: 100.00, precision: 1.0000, recall: 1.0000, f1: 1.0000
[test] loss: 0.3587, acc: 100.00, precision: 1.0000, recall: 1.0000, f1: 1.0000
Training time: 402.46 seconds
best loss: 0.3587, best acc: 100.00
log saved: lert_lstm_textcnn_attention_25-01-06_11-07-29.log
