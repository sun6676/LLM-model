> creating model roberta
> training arguments:
>>> num_classes: 2
>>> model_name: roberta
>>> method_name: lstm_textcnn_attention
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 1e-05
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1727927667380
>>> checkpoint_dir: ./checkpoints
>>> log_name: roberta_lstm_textcnn_attention_24-10-03_11-54-27.log
尝试从检查点继续训练: ./checkpoints\best_model.pth
没有找到检查点文件，将从头开始训练。
新最佳模型已保存于: ./checkpoints\best_model_epoch1_acc87.58_loss0.4365.pth
1/10 - 10.00%
[train] loss: 0.5565, acc: 74.79, precision: 0.7611, recall: 0.7479, f1: 0.7446
[test] loss: 0.4365, acc: 87.58, precision: 0.8796, recall: 0.8758, f1: 0.8757
