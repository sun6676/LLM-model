> creating model mamba2
> training arguments:
>>> num_classes: 2
>>> model_name: mamba2
>>> method_name: xlstm
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 1e-05
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1728977131518
>>> checkpoint_dir: ./checkpoints
>>> log_name: mamba2_xlstm_24-10-15_15-25-30.log
